{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa73664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:54:36.581527Z",
     "start_time": "2021-09-25T15:54:36.573555Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autowoe import AutoWoE\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "THRESHOLD = 0.15\n",
    "NEGATIVE_WEIGHT = 1.1\n",
    "\n",
    "def deviation_metric_one_sample(y_true: typing.Union[float, int], y_pred: typing.Union[float, int]) -> float:\n",
    "    \"\"\"\n",
    "    Реализация кастомной метрики для хакатона.\n",
    "\n",
    "    :param y_true: float, реальная цена\n",
    "    :param y_pred: float, предсказанная цена\n",
    "    :return: float, значение метрики\n",
    "    \"\"\"\n",
    "    deviation = (y_pred - y_true) / np.maximum(1e-8, y_true)\n",
    "    if np.abs(deviation) <= THRESHOLD:\n",
    "        return 0\n",
    "    elif deviation <= - 4 * THRESHOLD:\n",
    "        return 9 * NEGATIVE_WEIGHT\n",
    "    elif deviation < -THRESHOLD:\n",
    "        return NEGATIVE_WEIGHT * ((deviation / THRESHOLD) + 1) ** 2\n",
    "    elif deviation < 4 * THRESHOLD:\n",
    "        return ((deviation / THRESHOLD) - 1) ** 2\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "\n",
    "def deviation_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.array([deviation_metric_one_sample(y_true[n], y_pred[n]) for n in range(len(y_true))]).mean()\n",
    "\n",
    "def median_absolute_percentage_error(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.median(np.abs(y_pred-y_true)/y_true)\n",
    "\n",
    "def metrics_stat(y_true: np.array, y_pred: np.array) -> typing.Dict[str,float]:\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mdape = median_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    raif_metric = deviation_metric(y_true, y_pred)\n",
    "    return {'mape':mape, 'mdape':mdape, 'rmse': rmse, 'r2': r2, 'raif_metric':raif_metric}\n",
    "\n",
    "def deviation_metric_vec(y_true: np.array, y_pred: np.array) -> float:\n",
    "    deviation = (y_pred - y_true) / np.maximum(1e-8, y_true)\n",
    "    \n",
    "    metr = deviation * 0.0 + 9\n",
    "    \n",
    "    metr[np.abs(deviation) <= THRESHOLD] = 0\n",
    "    \n",
    "    metr[deviation <= - 4 * THRESHOLD] = 9 * NEGATIVE_WEIGHT\n",
    "    \n",
    "    mask = (-4 * THRESHOLD < deviation) & (deviation < -THRESHOLD)\n",
    "    metr[mask] = NEGATIVE_WEIGHT * ((deviation[mask] / THRESHOLD) + 1) ** 2\n",
    "    \n",
    "    mask = (deviation < 4 * THRESHOLD) & (deviation > THRESHOLD)\n",
    "    metr[mask] = ((deviation[mask] / THRESHOLD) - 1) ** 2\n",
    "    \n",
    "    return metr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8187174a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:35.805198Z",
     "start_time": "2021-09-25T15:51:35.801173Z"
    }
   },
   "outputs": [],
   "source": [
    "TARGET = 'per_square_meter_price'\n",
    "\n",
    "cat_features = ['region', 'street', 'city', 'realty_type']\n",
    "features = cat_features + ['floor', 'osm_amenity_points_in_0.001',\n",
    "       'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "       'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "       'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "       'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "       'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "       'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "      'osm_city_nearest_population',\n",
    "       'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "       'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "       'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "       'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "       'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "       'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "       'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "       'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "       'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "       'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "       'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "       'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "       'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "       'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "       'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "       'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "       'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "       'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "       'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "       'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "       'osm_transport_stop_points_in_0.0075',\n",
    "       'osm_transport_stop_points_in_0.01',\n",
    "       'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "       'reform_house_population_1000', 'reform_house_population_500',\n",
    "       'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "       'reform_mean_year_building_1000', 'reform_mean_year_building_500','total_square']\n",
    "TARGET2 = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d04061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:37.883033Z",
     "start_time": "2021-09-25T15:51:35.806209Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asciishell/raif/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c038a85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:40.091591Z",
     "start_time": "2021-09-25T15:51:37.884669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6666a30fcb4a5c82759514f6a364f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asciishell/raif/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "f = 'score_knn_5'\n",
    "test[f] = 0\n",
    "oof_pred = np.zeros_like(train[TARGET], dtype=np.float64) * np.nan\n",
    "kfold = StratifiedKFold(n_splits=5 , shuffle=True, random_state=42)\n",
    "clfs = []\n",
    "for train_idx, valid_idx in tqdm(kfold.split(train[TARGET], train['city']), total=kfold.n_splits):\n",
    "    train_data, valid_data = train.loc[train_idx, ['lat', 'lng']].values, train.loc[valid_idx, ['lat', 'lng']].values\n",
    "    train_target, valid_target = train.loc[train_idx, TARGET], train.loc[valid_idx, TARGET]\n",
    "    clf = KNeighborsRegressor(5)\n",
    "    clf.fit(train_data, train_target)\n",
    "    oof_pred[valid_idx] = clf.predict(valid_data)\n",
    "    test[f] += clf.predict(test[['lat', 'lng']].values) / kfold.n_splits\n",
    "    clfs.append(clf)\n",
    "train[f] = oof_pred\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98a3316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:40.136686Z",
     "start_time": "2021-09-25T15:51:40.092831Z"
    }
   },
   "outputs": [],
   "source": [
    "street_mapper = train['street'].value_counts().to_dict()\n",
    "street_mapper = {k: i for i, (k, v) in enumerate(street_mapper.items(), start=1) if v > 10}\n",
    "street_mapper = defaultdict(lambda: 0, street_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82856109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:40.228438Z",
     "start_time": "2021-09-25T15:51:40.137858Z"
    }
   },
   "outputs": [],
   "source": [
    "train['street'] = train['street'].map(street_mapper)\n",
    "test['street'] = test['street'].map(street_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c710187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:40.233054Z",
     "start_time": "2021-09-25T15:51:40.229589Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_floor(x):\n",
    "    if not isinstance(x, str) and np.isnan(x):\n",
    "        return -10\n",
    "    x = str(x).strip().replace('этаж', '').replace('-й', '').replace('цоколь', '-1').replace('подвал', '-1')\n",
    "    if x.count(',') > 0 or x.count('+') > 0:\n",
    "        return 100 + x.count(',') +  x.count('+')\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except ValueError:\n",
    "        return -11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35356ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:40.663498Z",
     "start_time": "2021-09-25T15:51:40.234541Z"
    }
   },
   "outputs": [],
   "source": [
    "train['floor'] = train['floor'].map(parse_floor)\n",
    "test['floor'] = test['floor'].map(parse_floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "375cb788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:51:41.202650Z",
     "start_time": "2021-09-25T15:51:40.665219Z"
    }
   },
   "outputs": [],
   "source": [
    "train[cat_features] = train[cat_features].astype(str).fillna('__NAN__')\n",
    "test[cat_features] = test[cat_features].astype(str).fillna('__NAN__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2602b615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:59:05.787474Z",
     "start_time": "2021-09-25T15:59:05.772259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KBinsDiscretizer(encode='ordinal', n_bins=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "est.fit(train[TARGET].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1910e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:59:07.163171Z",
     "start_time": "2021-09-25T15:59:07.151915Z"
    }
   },
   "outputs": [],
   "source": [
    "x = est.transform(train[TARGET].values.reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d8ad0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T15:59:07.601526Z",
     "start_time": "2021-09-25T15:59:07.596315Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_oof_and_test_pred(tr, real_te):\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "    oof_preds_woe = np.zeros(len(tr))\n",
    "    real_test_preds_woe = np.zeros(len(real_te))\n",
    "\n",
    "    y = tr[TARGET2].values\n",
    "\n",
    "    for fold, (train_idx, val_idx) in tqdm(enumerate(skf.split(y, y)), total=5):\n",
    "\n",
    "        X_tr, X_val = tr.iloc[train_idx, :], tr.iloc[val_idx, :]\n",
    "\n",
    "        auto_woe = AutoWoE(monotonic=False,\n",
    "                           max_bin_count=10,\n",
    "                           vif_th=10.,\n",
    "                           imp_th=0,\n",
    "                           th_const=32,\n",
    "                           force_single_split=True,\n",
    "                           min_bin_size = 0.005,\n",
    "                           oof_woe=True,\n",
    "                           n_folds=5,\n",
    "                           n_jobs=8,\n",
    "                           regularized_refit=True,\n",
    "                           verbose=0)\n",
    "\n",
    "        auto_woe.fit(X_tr, target_name=TARGET2)\n",
    "\n",
    "        val_pred = auto_woe.predict_proba(X_val)\n",
    "        print(\"FOLD {}, AUC_SCORE = {:.5f}\".format(fold, roc_auc_score(X_val[TARGET2], val_pred)))\n",
    "\n",
    "        oof_preds_woe[val_idx] = val_pred\n",
    "        real_test_preds_woe += auto_woe.predict_proba(real_te) / 5\n",
    "\n",
    "    print(\"SCORE AUC_TRAIN = {:.5f}\".format(roc_auc_score(train[TARGET2], oof_preds_woe)))\n",
    "    \n",
    "    return oof_preds_woe, real_test_preds_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c10ec3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T21:10:56.711555Z",
     "start_time": "2021-09-25T15:59:11.697882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b3df2b5bf4467bb65ada85f11b2f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17895, number of negative: 161171\n",
      "[LightGBM] [Info] Total Bins 15281\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099935 -> initscore=-2.197945\n",
      "[LightGBM] [Info] Start training from score -2.197945\n",
      "FOLD 0, AUC_SCORE = 0.88362\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17842, number of negative: 161224\n",
      "[LightGBM] [Info] Total Bins 15261\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099639 -> initscore=-2.201239\n",
      "[LightGBM] [Info] Start training from score -2.201239\n",
      "FOLD 1, AUC_SCORE = 0.87727\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17956, number of negative: 161111\n",
      "[LightGBM] [Info] Total Bins 15280\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100275 -> initscore=-2.194169\n",
      "[LightGBM] [Info] Start training from score -2.194169\n",
      "FOLD 2, AUC_SCORE = 0.87990\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17876, number of negative: 161191\n",
      "[LightGBM] [Info] Total Bins 15287\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099829 -> initscore=-2.199131\n",
      "[LightGBM] [Info] Start training from score -2.199131\n",
      "FOLD 3, AUC_SCORE = 0.87921\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17993, number of negative: 161074\n",
      "[LightGBM] [Info] Total Bins 15290\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100482 -> initscore=-2.191881\n",
      "[LightGBM] [Info] Start training from score -2.191881\n",
      "FOLD 4, AUC_SCORE = 0.87862\n",
      "SCORE AUC_TRAIN = 0.87972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddd1643c0d04616974194ad0570c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17830, number of negative: 161236\n",
      "[LightGBM] [Info] Total Bins 15267\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099572 -> initscore=-2.201987\n",
      "[LightGBM] [Info] Start training from score -2.201987\n",
      "FOLD 0, AUC_SCORE = 0.82321\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17861, number of negative: 161205\n",
      "[LightGBM] [Info] Total Bins 15304\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099745 -> initscore=-2.200057\n",
      "[LightGBM] [Info] Start training from score -2.200057\n",
      "FOLD 1, AUC_SCORE = 0.82082\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17945, number of negative: 161122\n",
      "[LightGBM] [Info] Total Bins 15266\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100214 -> initscore=-2.194850\n",
      "[LightGBM] [Info] Start training from score -2.194850\n",
      "FOLD 2, AUC_SCORE = 0.82343\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17972, number of negative: 161095\n",
      "[LightGBM] [Info] Total Bins 15255\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100365 -> initscore=-2.193179\n",
      "[LightGBM] [Info] Start training from score -2.193179\n",
      "FOLD 3, AUC_SCORE = 0.82301\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17912, number of negative: 161155\n",
      "[LightGBM] [Info] Total Bins 15289\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100030 -> initscore=-2.196896\n",
      "[LightGBM] [Info] Start training from score -2.196896\n",
      "FOLD 4, AUC_SCORE = 0.82259\n",
      "SCORE AUC_TRAIN = 0.82239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e9872c7cd349339e220f4066155291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17998, number of negative: 161068\n",
      "[LightGBM] [Info] Total Bins 15249\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100510 -> initscore=-2.191566\n",
      "[LightGBM] [Info] Start training from score -2.191566\n",
      "FOLD 0, AUC_SCORE = 0.78564\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17954, number of negative: 161112\n",
      "[LightGBM] [Info] Total Bins 15274\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100265 -> initscore=-2.194287\n",
      "[LightGBM] [Info] Start training from score -2.194287\n",
      "FOLD 1, AUC_SCORE = 0.78252\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17938, number of negative: 161129\n",
      "[LightGBM] [Info] Total Bins 15293\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100175 -> initscore=-2.195284\n",
      "[LightGBM] [Info] Start training from score -2.195284\n",
      "FOLD 2, AUC_SCORE = 0.78259\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17887, number of negative: 161180\n",
      "[LightGBM] [Info] Total Bins 15274\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099890 -> initscore=-2.198448\n",
      "[LightGBM] [Info] Start training from score -2.198448\n",
      "FOLD 3, AUC_SCORE = 0.78379\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17985, number of negative: 161082\n",
      "[LightGBM] [Info] Total Bins 15262\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100437 -> initscore=-2.192375\n",
      "[LightGBM] [Info] Start training from score -2.192375\n",
      "FOLD 4, AUC_SCORE = 0.77860\n",
      "SCORE AUC_TRAIN = 0.78206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9816c4eb4ff4ba1a286626eddea6477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17901, number of negative: 161165\n",
      "[LightGBM] [Info] Total Bins 15248\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099969 -> initscore=-2.197572\n",
      "[LightGBM] [Info] Start training from score -2.197572\n",
      "FOLD 0, AUC_SCORE = 0.76841\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17921, number of negative: 161145\n",
      "[LightGBM] [Info] Total Bins 15273\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100080 -> initscore=-2.196331\n",
      "[LightGBM] [Info] Start training from score -2.196331\n",
      "FOLD 1, AUC_SCORE = 0.76932\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17904, number of negative: 161163\n",
      "[LightGBM] [Info] Total Bins 15282\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099985 -> initscore=-2.197392\n",
      "[LightGBM] [Info] Start training from score -2.197392\n",
      "FOLD 2, AUC_SCORE = 0.77580\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17919, number of negative: 161148\n",
      "[LightGBM] [Info] Total Bins 15249\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100069 -> initscore=-2.196462\n",
      "[LightGBM] [Info] Start training from score -2.196462\n",
      "FOLD 3, AUC_SCORE = 0.77319\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17982, number of negative: 161085\n",
      "[LightGBM] [Info] Total Bins 15266\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100421 -> initscore=-2.192561\n",
      "[LightGBM] [Info] Start training from score -2.192561\n",
      "FOLD 4, AUC_SCORE = 0.77533\n",
      "SCORE AUC_TRAIN = 0.77222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da22181defd849299e9c6a7a2ebff00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 18049, number of negative: 161017\n",
      "[LightGBM] [Info] Total Bins 15241\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100795 -> initscore=-2.188420\n",
      "[LightGBM] [Info] Start training from score -2.188420\n",
      "FOLD 0, AUC_SCORE = 0.77285\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17988, number of negative: 161078\n",
      "[LightGBM] [Info] Total Bins 15271\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100455 -> initscore=-2.192184\n",
      "[LightGBM] [Info] Start training from score -2.192184\n",
      "FOLD 1, AUC_SCORE = 0.77621\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17913, number of negative: 161154\n",
      "[LightGBM] [Info] Total Bins 15273\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100035 -> initscore=-2.196834\n",
      "[LightGBM] [Info] Start training from score -2.196834\n",
      "FOLD 2, AUC_SCORE = 0.77292\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17927, number of negative: 161140\n",
      "[LightGBM] [Info] Total Bins 15261\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100113 -> initscore=-2.195966\n",
      "[LightGBM] [Info] Start training from score -2.195966\n",
      "FOLD 3, AUC_SCORE = 0.77329\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 18037, number of negative: 161030\n",
      "[LightGBM] [Info] Total Bins 15274\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100728 -> initscore=-2.189165\n",
      "[LightGBM] [Info] Start training from score -2.189165\n",
      "FOLD 4, AUC_SCORE = 0.77124\n",
      "SCORE AUC_TRAIN = 0.77329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbb1551fc884c38a6d4f2327bb3c4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17909, number of negative: 161157\n",
      "[LightGBM] [Info] Total Bins 15275\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100013 -> initscore=-2.197076\n",
      "[LightGBM] [Info] Start training from score -2.197076\n",
      "FOLD 0, AUC_SCORE = 0.79143\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17813, number of negative: 161253\n",
      "[LightGBM] [Info] Total Bins 15272\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099477 -> initscore=-2.203046\n",
      "[LightGBM] [Info] Start training from score -2.203046\n",
      "FOLD 1, AUC_SCORE = 0.79069\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 18034, number of negative: 161033\n",
      "[LightGBM] [Info] Total Bins 15248\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100711 -> initscore=-2.189350\n",
      "[LightGBM] [Info] Start training from score -2.189350\n",
      "FOLD 2, AUC_SCORE = 0.78815\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17863, number of negative: 161204\n",
      "[LightGBM] [Info] Total Bins 15260\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099756 -> initscore=-2.199939\n",
      "[LightGBM] [Info] Start training from score -2.199939\n",
      "FOLD 3, AUC_SCORE = 0.78678\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17905, number of negative: 161162\n",
      "[LightGBM] [Info] Total Bins 15271\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099991 -> initscore=-2.197330\n",
      "[LightGBM] [Info] Start training from score -2.197330\n",
      "FOLD 4, AUC_SCORE = 0.78868\n",
      "SCORE AUC_TRAIN = 0.78917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad415deb7bf40f88bc4cc828da3041a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17814, number of negative: 161252\n",
      "[LightGBM] [Info] Total Bins 15240\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099483 -> initscore=-2.202984\n",
      "[LightGBM] [Info] Start training from score -2.202984\n",
      "FOLD 0, AUC_SCORE = 0.81005\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17929, number of negative: 161137\n",
      "[LightGBM] [Info] Total Bins 15301\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100125 -> initscore=-2.195835\n",
      "[LightGBM] [Info] Start training from score -2.195835\n",
      "FOLD 1, AUC_SCORE = 0.81263\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17892, number of negative: 161175\n",
      "[LightGBM] [Info] Total Bins 15275\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099918 -> initscore=-2.198137\n",
      "[LightGBM] [Info] Start training from score -2.198137\n",
      "FOLD 2, AUC_SCORE = 0.81487\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17759, number of negative: 161308\n",
      "[LightGBM] [Info] Total Bins 15276\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099175 -> initscore=-2.206423\n",
      "[LightGBM] [Info] Start training from score -2.206423\n",
      "FOLD 3, AUC_SCORE = 0.81497\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17927, number of negative: 161140\n",
      "[LightGBM] [Info] Total Bins 15282\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100113 -> initscore=-2.195966\n",
      "[LightGBM] [Info] Start training from score -2.195966\n",
      "FOLD 4, AUC_SCORE = 0.81488\n",
      "SCORE AUC_TRAIN = 0.81345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b804a2d801494a91842f3247464aa99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17850, number of negative: 161216\n",
      "[LightGBM] [Info] Total Bins 15279\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099684 -> initscore=-2.200742\n",
      "[LightGBM] [Info] Start training from score -2.200742\n",
      "FOLD 0, AUC_SCORE = 0.85257\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17829, number of negative: 161237\n",
      "[LightGBM] [Info] Total Bins 15260\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099567 -> initscore=-2.202049\n",
      "[LightGBM] [Info] Start training from score -2.202049\n",
      "FOLD 1, AUC_SCORE = 0.85491\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17899, number of negative: 161168\n",
      "[LightGBM] [Info] Total Bins 15255\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099957 -> initscore=-2.197702\n",
      "[LightGBM] [Info] Start training from score -2.197702\n",
      "FOLD 2, AUC_SCORE = 0.85186\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17917, number of negative: 161150\n",
      "[LightGBM] [Info] Total Bins 15246\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100058 -> initscore=-2.196586\n",
      "[LightGBM] [Info] Start training from score -2.196586\n",
      "FOLD 3, AUC_SCORE = 0.85313\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17992, number of negative: 161075\n",
      "[LightGBM] [Info] Total Bins 15274\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100476 -> initscore=-2.191943\n",
      "[LightGBM] [Info] Start training from score -2.191943\n",
      "FOLD 4, AUC_SCORE = 0.85027\n",
      "SCORE AUC_TRAIN = 0.85268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aae194a2a84cad92072620fe38ef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17891, number of negative: 161175\n",
      "[LightGBM] [Info] Total Bins 15266\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099913 -> initscore=-2.198193\n",
      "[LightGBM] [Info] Start training from score -2.198193\n",
      "FOLD 0, AUC_SCORE = 0.91212\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17943, number of negative: 161123\n",
      "[LightGBM] [Info] Total Bins 15284\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100203 -> initscore=-2.194968\n",
      "[LightGBM] [Info] Start training from score -2.194968\n",
      "FOLD 1, AUC_SCORE = 0.91080\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17764, number of negative: 161303\n",
      "[LightGBM] [Info] Total Bins 15297\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099203 -> initscore=-2.206111\n",
      "[LightGBM] [Info] Start training from score -2.206111\n",
      "FOLD 2, AUC_SCORE = 0.91476\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17841, number of negative: 161226\n",
      "[LightGBM] [Info] Total Bins 15269\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099633 -> initscore=-2.201308\n",
      "[LightGBM] [Info] Start training from score -2.201308\n",
      "FOLD 3, AUC_SCORE = 0.91561\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17909, number of negative: 161158\n",
      "[LightGBM] [Info] Total Bins 15248\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100013 -> initscore=-2.197082\n",
      "[LightGBM] [Info] Start training from score -2.197082\n",
      "FOLD 4, AUC_SCORE = 0.91572\n",
      "SCORE AUC_TRAIN = 0.91359\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1779208575e64d01b06f280e4f6592cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17882, number of negative: 161184\n",
      "[LightGBM] [Info] Total Bins 15266\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099863 -> initscore=-2.198752\n",
      "[LightGBM] [Info] Start training from score -2.198752\n",
      "FOLD 0, AUC_SCORE = 0.97044\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17868, number of negative: 161198\n",
      "[LightGBM] [Info] Total Bins 15283\n",
      "[LightGBM] [Info] Number of data: 179066, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099784 -> initscore=-2.199622\n",
      "[LightGBM] [Info] Start training from score -2.199622\n",
      "FOLD 1, AUC_SCORE = 0.96983\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17971, number of negative: 161096\n",
      "[LightGBM] [Info] Total Bins 15245\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100359 -> initscore=-2.193241\n",
      "[LightGBM] [Info] Start training from score -2.193241\n",
      "FOLD 2, AUC_SCORE = 0.96930\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17932, number of negative: 161135\n",
      "[LightGBM] [Info] Total Bins 15279\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100141 -> initscore=-2.195656\n",
      "[LightGBM] [Info] Start training from score -2.195656\n",
      "FOLD 3, AUC_SCORE = 0.96981\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17903, number of negative: 161164\n",
      "[LightGBM] [Info] Total Bins 15268\n",
      "[LightGBM] [Info] Number of data: 179067, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099979 -> initscore=-2.197454\n",
      "[LightGBM] [Info] Start training from score -2.197454\n",
      "FOLD 4, AUC_SCORE = 0.97028\n",
      "SCORE AUC_TRAIN = 0.96992\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    train[TARGET2] = (x == i).astype(int)\n",
    "    oof_preds_woe, real_test_preds_woe = get_oof_and_test_pred(train[[*features, TARGET2]], test[[*features]])\n",
    "    train[f'oof_woe_{i}'] = oof_preds_woe\n",
    "    test[f'oof_woe_{i}'] = real_test_preds_woe\n",
    "\n",
    "    train[f'rank_oof_woe_{i}'] = rankdata(oof_preds_woe)\n",
    "    test[f'rank_oof_woe_{i}'] = rankdata(real_test_preds_woe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a2ba8c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T21:18:02.082059Z",
     "start_time": "2021-09-25T21:18:02.079571Z"
    }
   },
   "outputs": [],
   "source": [
    "woe_features = np.array([[f'oof_woe_{i}'] for i in np.arange(10)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f85a8f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T21:18:09.034290Z",
     "start_time": "2021-09-25T21:18:04.063398Z"
    }
   },
   "outputs": [],
   "source": [
    "train[woe_features].to_csv('data/train_woe_features.csv', index=False)\n",
    "test[woe_features].to_csv('data/test_woe_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12384cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
